{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Se descargo los data set en formato .xlsx algunos de estos tiene varias hojas por data set  para realizar el respectivo análisis debemos convertimos a formato csv \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Internet.xlsx para extraer las diferentes hojas que lo conforman y las trasformamos a formato .csv y las guardamos en la carpeta internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La hoja de nombre 'Acc_vel_loc_sinrangos' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Acc_vel_loc_sinrangos.csv\n",
      "La hoja de nombre 'Velocidad_sin_Rangos' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Velocidad_sin_Rangos.csv\n",
      "La hoja de nombre 'Accesos_tecnologia_localidad' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos_tecnologia_localidad.csv\n",
      "La hoja de nombre 'Velocidad % por prov' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Velocidad % por prov.csv\n",
      "La hoja de nombre 'Totales VMD' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales VMD.csv\n",
      "La hoja de nombre 'Totales Accesos Por Tecnología' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Accesos Por Tecnología.csv\n",
      "La hoja de nombre 'Accesos Por Tecnología' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos Por Tecnología.csv\n",
      "La hoja de nombre 'Penetración-poblacion' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetración-poblacion.csv\n",
      "La hoja de nombre 'Penetracion-hogares' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetracion-hogares.csv\n",
      "La hoja de nombre 'Penetracion-totales' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetracion-totales.csv\n",
      "La hoja de nombre 'Totales Accesos por rango' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Accesos por rango.csv\n",
      "La hoja de nombre 'Accesos por rangos' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos por rangos.csv\n",
      "La hoja de nombre 'Dial-BAf' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Dial-BAf.csv\n",
      "La hoja de nombre 'Totales Dial-BAf' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Dial-BAf.csv\n",
      "La hoja de nombre 'Ingresos ' a sido combredtida aconvertida a H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Ingresos .csv\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el data set Internet en formato .xlsx\n",
    "excel_file =r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .xlsx/Internet.xlsx'\n",
    "\n",
    "# Leemos todas las hojas del archivo Excel\n",
    "hojas = pd.read_excel(excel_file, sheet_name=None)\n",
    "\n",
    "# Convertimos cada hoja a un archivo CSV\n",
    "csv_files = []\n",
    "for nombre_hoja, datos_hoja in hojas.items():\n",
    "    # Definmos el nombre del archivo CSV basado en el nombre de la hoja\n",
    "    nombre_csv = f\"H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/{nombre_hoja}.csv\"\n",
    "    # Guardamos cada hoja en un archivo CSV\n",
    "    datos_hoja.to_csv(nombre_csv, index=False)\n",
    "    csv_files.append(nombre_csv)\n",
    "    print(f\"La hoja de nombre '{nombre_hoja}' a sido combredtida aconvertida a {nombre_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Acc_vel_loc_sinrangos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Internet .csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Acc_vel_loc_sinrangos.csv\n",
      "        Partido   Localidad  link Indec Velocidad (Mbps)  Provincia  Accesos\n",
      "0  BUENOS AIRES  25 de Mayo  25 de Mayo          6854100       0.00      1.0\n",
      "1  BUENOS AIRES  25 de Mayo  25 de Mayo          6854100       0.50      2.0\n",
      "2  BUENOS AIRES  25 de Mayo  25 de Mayo          6854100       0.75     19.0\n",
      "3  BUENOS AIRES  25 de Mayo  25 de Mayo          6854100       3.00     85.0\n",
      "4  BUENOS AIRES  25 de Mayo  25 de Mayo          6854100       3.50    145.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18864 entries, 0 to 18863\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Partido           18864 non-null  object \n",
      " 1   Localidad         18864 non-null  object \n",
      " 2   link Indec        18863 non-null  object \n",
      " 3   Velocidad (Mbps)  18864 non-null  object \n",
      " 4   Provincia         18864 non-null  float64\n",
      " 5   Accesos           18857 non-null  float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 884.4+ KB\n",
      "None\n",
      "          Provincia        Accesos\n",
      "count  18864.000000   18857.000000\n",
      "mean      66.866042     612.828499\n",
      "std      178.987138    6283.359677\n",
      "min        0.000000   -5582.000000\n",
      "25%        3.000000       3.000000\n",
      "50%       10.000000      26.000000\n",
      "75%       30.000000     180.000000\n",
      "max     1024.000000  576789.000000\n",
      "Dimensiones del dataframe: (18864, 6)\n",
      "Valores nulos por columna\n",
      "Partido             0\n",
      "Localidad           0\n",
      "link Indec          1\n",
      "Velocidad (Mbps)    0\n",
      "Provincia           0\n",
      "Accesos             7\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Partido             0.000000\n",
      "Localidad           0.000000\n",
      "link Indec          0.005301\n",
      "Velocidad (Mbps)    0.000000\n",
      "Provincia           0.000000\n",
      "Accesos             0.037108\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Acc_vel_loc_sinrangos.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\")\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una ves detectado si hay valores faltantes los cambiaremos por none  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna\n",
      "Partido             0\n",
      "Localidad           0\n",
      "link Indec          1\n",
      "Velocidad (Mbps)    0\n",
      "Provincia           0\n",
      "Accesos             7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cambiamos valores faltantes por None\n",
    "df = df.where(pd.notnull(df), None)\n",
    "df.replace(r\"^\\s*$\", None, regex=True, inplace=True)\n",
    "\n",
    "\n",
    "# Análisis de valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un columna id Provincia y Id Localidad se elimina las columnas link id(representan pequeñas localidades no las considero relevantes) y provincia(No  encuentro que representa por eso la veo de baja relevancia),además se ordena las colunas en base a su relevancia\n",
    "En  columna localidad se repiten las localidades por lo que sumamos los datos de acceso y promediamos los de velocidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provincias en Argentina: ['BUENOS AIRES' 'CABA' 'CATAMARCA' 'CHACO' 'CHUBUT' 'CORDOBA' 'CORRIENTES'\n",
      " 'ENTRE RIOS' 'FORMOSA' 'JUJUY' 'LA PAMPA' 'LA RIOJA' 'MENDOZA' 'MISIONES'\n",
      " 'NEUQUEN' 'RIO NEGRO' 'SALTA' 'SAN JUAN' 'SAN LUIS' 'SANTA CRUZ'\n",
      " 'SANTA FE' 'SANTIAGO DEL ESTERO' 'TIERRA DEL FUEGO' 'TUCUMAN']\n",
      "Número total de provincias: 24\n",
      "Número total de localidades: 435\n",
      "   Id_Provincia     Provincia  Id_Localidad   Localidad  Velocidad (Mbps)  \\\n",
      "0             1  BUENOS AIRES             1  25 de Mayo         6854100.0   \n",
      "1             1  BUENOS AIRES             1  25 de Mayo         6854100.0   \n",
      "2             1  BUENOS AIRES             1  25 de Mayo         6854100.0   \n",
      "3             1  BUENOS AIRES             1  25 de Mayo         6854100.0   \n",
      "4             1  BUENOS AIRES             1  25 de Mayo         6854100.0   \n",
      "\n",
      "   Accesos  \n",
      "0      1.0  \n",
      "1      2.0  \n",
      "2     19.0  \n",
      "3     85.0  \n",
      "4    145.0  \n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Acc_vel_loc_sinrangos.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Eliminamos columnas poco relevantes\n",
    "df.drop(columns=['Provincia', 'link Indec'], inplace=True)\n",
    "\n",
    "# Reemplazamos valores vacíos en 'Accesos' con 0 o NULL\n",
    "df['Accesos'] = df['Accesos'].fillna(0)  # Cambia a None si deseas NULL\n",
    "\n",
    "# Cambiamos el nombre de la columna Partido a Provincia\n",
    "df.rename(columns={'Partido': 'Provincia'}, inplace=True)\n",
    "\n",
    "# Identificamos todas las provincias en el dataset\n",
    "provincias = df['Provincia'].unique()\n",
    "print(\"Provincias en Argentina:\", provincias)\n",
    "print(\"Número total de provincias:\", len(provincias))\n",
    "\n",
    "# Creamos un diccionario de ID únicos para cada provincia, comenzando desde 1\n",
    "provincia_id_map = {provincia: idx + 1 for idx, provincia in enumerate(provincias)}\n",
    "\n",
    "# Creamos la columna Id_Provincia usando el diccionario\n",
    "df['Id_Provincia'] = df['Provincia'].map(provincia_id_map)\n",
    "\n",
    "# Identificamos todas las localidades en el dataset\n",
    "localidades = df['Localidad'].unique()\n",
    "print(\"Número total de localidades:\", len(localidades))\n",
    "\n",
    "# Creamos un diccionario único para cada localidad comenzando en 1\n",
    "localidad_id_map = {localidad: idx + 1 for idx, localidad in enumerate(localidades)}\n",
    "\n",
    "# Creamos la columna Id_Localidad usando el diccionario\n",
    "df['Id_Localidad'] = df['Localidad'].map(localidad_id_map)\n",
    "\n",
    "# Ordenamos el dataset según el orden de columnas\n",
    "column_order = ['Id_Provincia', 'Provincia', 'Id_Localidad', 'Localidad', 'Velocidad (Mbps)', 'Accesos']\n",
    "df = df[column_order]\n",
    "\n",
    "# Configuramos pandas para mostrar todos los dígitos en la salida sin notación científica\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "\n",
    "#Nos aseguramos que todos los datos de la columna velocidad se encuentren en un formato numerico\n",
    "df['Velocidad (Mbps)'] = pd.to_numeric(df['Velocidad (Mbps)'], errors='coerce')\n",
    "\n",
    "# Agrupamos y calculamos la suma de  datos de la columna 'Accesos' y el promedio de la columna  'Velocidad (Mbps)', redondeando a 1 decimal .Todo esto lo asemos por localidad\n",
    "df_grouped = df.groupby(['Id_Provincia', 'Provincia', 'Id_Localidad', 'Localidad'], as_index=False).agg({\n",
    "    'Accesos': 'sum',\n",
    "    'Velocidad (Mbps)': 'mean'\n",
    "})\n",
    "df_grouped['Velocidad (Mbps)'] = df_grouped['Velocidad (Mbps)'].round(1)\n",
    "\n",
    "\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Acc_vel_loc_sinrangos.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL rangos.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Accesos por rangos.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos por rangos.csv\n",
      "    Año  Trimestre        Provincia  HASTA 512 kbps  + 512 Kbps - 1 Mbps  \\\n",
      "0  2024          2     Buenos Aires         25287.0              23034.0   \n",
      "1  2024          2  Capital Federal           518.0               4122.0   \n",
      "2  2024          2        Catamarca            72.0                164.0   \n",
      "3  2024          2            Chaco           236.0                349.0   \n",
      "4  2024          2           Chubut           125.0               1139.0   \n",
      "\n",
      "   + 1 Mbps - 6 Mbps  + 6 Mbps - 10 Mbps  + 10 Mbps - 20 Mbps  \\\n",
      "0           222627.0            221660.0             244528.0   \n",
      "1            24539.0             40296.0              33158.0   \n",
      "2             2660.0              3093.0               3799.0   \n",
      "3            14594.0              8336.0               6208.0   \n",
      "4            43699.0             31971.0              22696.0   \n",
      "\n",
      "   + 20 Mbps - 30 Mbps  + 30 Mbps    OTROS     Total  \n",
      "0             106302.0  4020395.0 125547.0 4989380.0  \n",
      "1               5633.0  1355333.0      0.0 1463599.0  \n",
      "2               1279.0    63954.0     53.0   75074.0  \n",
      "3               6454.0   107707.0   3208.0  147092.0  \n",
      "4              19827.0    38212.0  16554.0  174223.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Año                  1000 non-null   int64  \n",
      " 1   Trimestre            1000 non-null   int64  \n",
      " 2   Provincia            1000 non-null   object \n",
      " 3   HASTA 512 kbps       1000 non-null   float64\n",
      " 4   + 512 Kbps - 1 Mbps  1000 non-null   float64\n",
      " 5   + 1 Mbps - 6 Mbps    1000 non-null   float64\n",
      " 6   + 6 Mbps - 10 Mbps   1000 non-null   float64\n",
      " 7   + 10 Mbps - 20 Mbps  1000 non-null   float64\n",
      " 8   + 20 Mbps - 30 Mbps  1000 non-null   float64\n",
      " 9   + 30 Mbps            1000 non-null   float64\n",
      " 10  OTROS                994 non-null    float64\n",
      " 11  Total                1000 non-null   float64\n",
      "dtypes: float64(9), int64(2), object(1)\n",
      "memory usage: 93.9+ KB\n",
      "None\n",
      "         Año  Trimestre  HASTA 512 kbps  + 512 Kbps - 1 Mbps  \\\n",
      "count 1000.0     1000.0          1000.0               1000.0   \n",
      "mean  2018.8        2.5          1953.3               8864.3   \n",
      "std      3.1        1.1         12676.6              20312.5   \n",
      "min   2014.0        1.0             6.0                  0.0   \n",
      "25%   2016.0        1.0            43.2                389.8   \n",
      "50%   2019.0        2.0           107.0               2061.0   \n",
      "75%   2021.0        3.0           466.2               6851.5   \n",
      "max   2024.0        4.0        238920.0             171244.5   \n",
      "\n",
      "       + 1 Mbps - 6 Mbps  + 6 Mbps - 10 Mbps  + 10 Mbps - 20 Mbps  \\\n",
      "count             1000.0              1000.0               1000.0   \n",
      "mean            132772.5             38408.5              37138.3   \n",
      "std             322256.9             64156.4              88290.7   \n",
      "min               1124.0                 0.0                  0.0   \n",
      "25%              23812.5              3876.8               2706.8   \n",
      "50%              42132.5             13932.0              10503.0   \n",
      "75%              83710.2             42593.5              26463.8   \n",
      "max            2299705.3            403575.0             886678.0   \n",
      "\n",
      "       + 20 Mbps - 30 Mbps  + 30 Mbps    OTROS     Total  \n",
      "count               1000.0     1000.0    994.0    1000.0  \n",
      "mean               20091.3   122209.8   6510.5  367909.4  \n",
      "std                69299.3   465750.0  15344.5  789934.8  \n",
      "min                    0.0        0.0  -1945.0   12406.0  \n",
      "25%                   43.8       15.0      0.0   62342.2  \n",
      "50%                 1658.0     4253.5    346.5  113620.5  \n",
      "75%                10109.2    43399.2   6830.8  196919.8  \n",
      "max               949093.0  4068292.0 125547.0 5044557.0  \n",
      "Dimensiones del dataframe: (1000, 12)\n",
      "Valores nulos por columna\n",
      "Año                    0\n",
      "Trimestre              0\n",
      "Provincia              0\n",
      "HASTA 512 kbps         0\n",
      "+ 512 Kbps - 1 Mbps    0\n",
      "+ 1 Mbps - 6 Mbps      0\n",
      "+ 6 Mbps - 10 Mbps     0\n",
      "+ 10 Mbps - 20 Mbps    0\n",
      "+ 20 Mbps - 30 Mbps    0\n",
      "+ 30 Mbps              0\n",
      "OTROS                  6\n",
      "Total                  0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Año                   0.0\n",
      "Trimestre             0.0\n",
      "Provincia             0.0\n",
      "HASTA 512 kbps        0.0\n",
      "+ 512 Kbps - 1 Mbps   0.0\n",
      "+ 1 Mbps - 6 Mbps     0.0\n",
      "+ 6 Mbps - 10 Mbps    0.0\n",
      "+ 10 Mbps - 20 Mbps   0.0\n",
      "+ 20 Mbps - 30 Mbps   0.0\n",
      "+ 30 Mbps             0.0\n",
      "OTROS                 0.6\n",
      "Total                 0.0\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos por rangos.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\")  # Muestra el nombre del archivo\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el formato de fecha para que sea un formato mas compatible con Python uniendo la columna Año con la columna trimestre  para ser remplasadas por Fecha y se crea la  columna Id_provincia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\n",
      "Provincias en Argentina: ['Buenos Aires' 'Capital Federal' 'Catamarca' 'Chaco' 'Chubut' 'Córdoba'\n",
      " 'Corrientes' 'Entre Ríos' 'Formosa' 'Jujuy' 'La Pampa' 'La Rioja'\n",
      " 'Mendoza' 'Misiones' 'Neuquén' 'Río Negro' 'Salta' 'San Juan' 'San Luis'\n",
      " 'Santa Cruz' 'Santa Fe' 'Santiago Del Estero' 'Tierra Del Fuego'\n",
      " 'Tucumán']\n",
      "Número total de provincias: 24\n",
      "   Id_Provincia        Provincia       Fecha  HASTA 512 kbps  \\\n",
      "0             1     Buenos Aires  2024-06-30         25287.0   \n",
      "1             2  Capital Federal  2024-06-30           518.0   \n",
      "2             3        Catamarca  2024-06-30            72.0   \n",
      "3             4            Chaco  2024-06-30           236.0   \n",
      "4             5           Chubut  2024-06-30           125.0   \n",
      "\n",
      "   + 512 Kbps - 1 Mbps  + 1 Mbps - 6 Mbps  + 6 Mbps - 10 Mbps  \\\n",
      "0              23034.0           222627.0            221660.0   \n",
      "1               4122.0            24539.0             40296.0   \n",
      "2                164.0             2660.0              3093.0   \n",
      "3                349.0            14594.0              8336.0   \n",
      "4               1139.0            43699.0             31971.0   \n",
      "\n",
      "   + 10 Mbps - 20 Mbps  + 20 Mbps - 30 Mbps  + 30 Mbps    OTROS     Total  \n",
      "0             244528.0             106302.0  4020395.0 125547.0 4989380.0  \n",
      "1              33158.0               5633.0  1355333.0      0.0 1463599.0  \n",
      "2               3799.0               1279.0    63954.0     53.0   75074.0  \n",
      "3               6208.0               6454.0   107707.0   3208.0  147092.0  \n",
      "4              22696.0              19827.0    38212.0  16554.0  174223.0  \n",
      "Archivo se guardo correctamente en: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos por rangos.csv\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el data set \n",
    "file_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos por rangos.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Mapeamos los trimestres al último día de cada trimestre\n",
    "trimestre_map = {1: \"03-31\", 2: \"06-30\", 3: \"09-30\", 4: \"12-31\"}\n",
    "\n",
    "# Convertimos 'Año' a cadena y mapear 'Trimestre' al último día del trimestre\n",
    "if 'Año' in df.columns and 'Trimestre' in df.columns:\n",
    "    df['Año'] = df['Año'].astype(str)\n",
    "    df['Trimestre'] = df['Trimestre'].map(trimestre_map)\n",
    "\n",
    "    # Creamos la columna 'Fecha' combinando 'Año' y 'Trimestre'\n",
    "    df['Fecha'] = pd.to_datetime(df['Año'] + \"-\" + df['Trimestre'])\n",
    "\n",
    "    # Borramos  las columnas 'Año' y 'Trimestre'\n",
    "    df.drop(columns=['Año', 'Trimestre'], inplace=True)\n",
    "\n",
    "    # Reordenamos las columnas \n",
    "    cols = ['Fecha'] + [col for col in df.columns if col != 'Fecha']\n",
    "    df = df[cols]\n",
    "else:\n",
    "    print(\"Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\")\n",
    "\n",
    "# Identificamos todas las provincias en el dataset\n",
    "provincias = df['Provincia'].unique()\n",
    "print(\"Provincias en Argentina:\", provincias)\n",
    "print(\"Número total de provincias:\", len(provincias))\n",
    "\n",
    "# Creamos un diccionario de ID únicos para cada provincia, comenzando desde 1\n",
    "provincia_id_map = {provincia: idx + 1 for idx, provincia in enumerate(provincias)}\n",
    "\n",
    "# Creamos la columna Id_Provincia usando el diccionario\n",
    "df['Id_Provincia'] = df['Provincia'].map(provincia_id_map)\n",
    "\n",
    "# Ordenamos el dataset según el orden de columnas\n",
    "column_order = ['Id_Provincia','Provincia', 'Fecha','HASTA 512 kbps','+ 512 Kbps - 1 Mbps','+ 1 Mbps - 6 Mbps','+ 6 Mbps - 10 Mbps','+ 10 Mbps - 20 Mbps','+ 20 Mbps - 30 Mbps','+ 30 Mbps','OTROS','Total']\n",
    "df = df[column_order]\n",
    "\n",
    "print(df.head()) \n",
    "\n",
    "# Guardar el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos por rangos.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Confirmación de guardado\n",
    "print(f\"Archivo se guardo correctamente en: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Tecnología.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Accesos Por Tecnología.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos Por Tecnología.csv\n",
      "   Id_Provincia        Provincia       Fecha  HASTA 512 kbps  \\\n",
      "0             1     Buenos Aires  2024-06-30         25287.0   \n",
      "1             2  Capital Federal  2024-06-30           518.0   \n",
      "2             3        Catamarca  2024-06-30            72.0   \n",
      "3             4            Chaco  2024-06-30           236.0   \n",
      "4             5           Chubut  2024-06-30           125.0   \n",
      "\n",
      "   + 512 Kbps - 1 Mbps  + 1 Mbps - 6 Mbps  + 6 Mbps - 10 Mbps  \\\n",
      "0              23034.0           222627.0            221660.0   \n",
      "1               4122.0            24539.0             40296.0   \n",
      "2                164.0             2660.0              3093.0   \n",
      "3                349.0            14594.0              8336.0   \n",
      "4               1139.0            43699.0             31971.0   \n",
      "\n",
      "   + 10 Mbps - 20 Mbps  + 20 Mbps - 30 Mbps  + 30 Mbps    OTROS     Total  \n",
      "0             244528.0             106302.0  4020395.0 125547.0 4989380.0  \n",
      "1              33158.0               5633.0  1355333.0      0.0 1463599.0  \n",
      "2               3799.0               1279.0    63954.0     53.0   75074.0  \n",
      "3               6208.0               6454.0   107707.0   3208.0  147092.0  \n",
      "4              22696.0              19827.0    38212.0  16554.0  174223.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Id_Provincia         1000 non-null   int64  \n",
      " 1   Provincia            1000 non-null   object \n",
      " 2   Fecha                1000 non-null   object \n",
      " 3   HASTA 512 kbps       1000 non-null   float64\n",
      " 4   + 512 Kbps - 1 Mbps  1000 non-null   float64\n",
      " 5   + 1 Mbps - 6 Mbps    1000 non-null   float64\n",
      " 6   + 6 Mbps - 10 Mbps   1000 non-null   float64\n",
      " 7   + 10 Mbps - 20 Mbps  1000 non-null   float64\n",
      " 8   + 20 Mbps - 30 Mbps  1000 non-null   float64\n",
      " 9   + 30 Mbps            1000 non-null   float64\n",
      " 10  OTROS                994 non-null    float64\n",
      " 11  Total                1000 non-null   float64\n",
      "dtypes: float64(9), int64(1), object(2)\n",
      "memory usage: 93.9+ KB\n",
      "None\n",
      "       Id_Provincia  HASTA 512 kbps  + 512 Kbps - 1 Mbps  + 1 Mbps - 6 Mbps  \\\n",
      "count        1000.0          1000.0               1000.0             1000.0   \n",
      "mean           12.4          1953.3               8864.3           132772.5   \n",
      "std             6.9         12676.6              20312.5           322256.9   \n",
      "min             1.0             6.0                  0.0             1124.0   \n",
      "25%             6.0            43.2                389.8            23812.5   \n",
      "50%            12.0           107.0               2061.0            42132.5   \n",
      "75%            18.0           466.2               6851.5            83710.2   \n",
      "max            24.0        238920.0             171244.5          2299705.3   \n",
      "\n",
      "       + 6 Mbps - 10 Mbps  + 10 Mbps - 20 Mbps  + 20 Mbps - 30 Mbps  \\\n",
      "count              1000.0               1000.0               1000.0   \n",
      "mean              38408.5              37138.3              20091.3   \n",
      "std               64156.4              88290.7              69299.3   \n",
      "min                   0.0                  0.0                  0.0   \n",
      "25%                3876.8               2706.8                 43.8   \n",
      "50%               13932.0              10503.0               1658.0   \n",
      "75%               42593.5              26463.8              10109.2   \n",
      "max              403575.0             886678.0             949093.0   \n",
      "\n",
      "       + 30 Mbps    OTROS     Total  \n",
      "count     1000.0    994.0    1000.0  \n",
      "mean    122209.8   6510.5  367909.4  \n",
      "std     465750.0  15344.5  789934.8  \n",
      "min          0.0  -1945.0   12406.0  \n",
      "25%         15.0      0.0   62342.2  \n",
      "50%       4253.5    346.5  113620.5  \n",
      "75%      43399.2   6830.8  196919.8  \n",
      "max    4068292.0 125547.0 5044557.0  \n",
      "Dimensiones del dataframe: (1000, 12)\n",
      "Valores nulos por columna\n",
      "Id_Provincia           0\n",
      "Provincia              0\n",
      "Fecha                  0\n",
      "HASTA 512 kbps         0\n",
      "+ 512 Kbps - 1 Mbps    0\n",
      "+ 1 Mbps - 6 Mbps      0\n",
      "+ 6 Mbps - 10 Mbps     0\n",
      "+ 10 Mbps - 20 Mbps    0\n",
      "+ 20 Mbps - 30 Mbps    0\n",
      "+ 30 Mbps              0\n",
      "OTROS                  6\n",
      "Total                  0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Id_Provincia          0.0\n",
      "Provincia             0.0\n",
      "Fecha                 0.0\n",
      "HASTA 512 kbps        0.0\n",
      "+ 512 Kbps - 1 Mbps   0.0\n",
      "+ 1 Mbps - 6 Mbps     0.0\n",
      "+ 6 Mbps - 10 Mbps    0.0\n",
      "+ 10 Mbps - 20 Mbps   0.0\n",
      "+ 20 Mbps - 30 Mbps   0.0\n",
      "+ 30 Mbps             0.0\n",
      "OTROS                 0.6\n",
      "Total                 0.0\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos Por Tecnología.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\")  \n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el formato de fecha para que sea un formato mas compatible con Python uniendo la columna fecha con la columna trimestre , ademas creamos la columna Id_Provincia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en Trimestre antes de limpieza: ['2' '1' '4' '3' '3 *' '2 *' '1 *' nan\n",
      " 'Los datos provinciales no coinciden a nivel nacional, ya que se rincorporó información que no contien apertuta a nivel geográfico.']\n",
      "Provincias en Argentina: ['Buenos Aires' 'Capital Federal' 'Catamarca' 'Chaco' 'Chubut' 'Córdoba'\n",
      " 'Corrientes' 'Entre Ríos' 'Formosa' 'Jujuy' 'La Pampa' 'La Rioja'\n",
      " 'Mendoza' 'Misiones' 'Neuquén' 'Río Negro' 'Salta' 'San Juan' 'San Luis'\n",
      " 'Santa Cruz' 'Santa Fe' 'Santiago Del Estero' 'Tierra Del Fuego'\n",
      " 'Tucumán' nan]\n",
      "Número total de provincias: 25\n",
      "   Id_Provincia        Provincia      Fecha     ADSL  Cablemodem  \\\n",
      "0             1     Buenos Aires 2024-06-30 214055.0   2722466.0   \n",
      "1             2  Capital Federal 2024-06-30  54102.0   1144781.0   \n",
      "2             3        Catamarca 2024-06-30   4951.0     10303.0   \n",
      "3             4            Chaco 2024-06-30   9448.0     57935.0   \n",
      "4             5           Chubut 2024-06-30  25955.0     80704.0   \n",
      "\n",
      "   Fibra óptica  Wireless   Otros     Total  \n",
      "0     1849476.0  138638.0 64745.0 4989380.0  \n",
      "1      230402.0    4493.0 29821.0 1463599.0  \n",
      "2       58355.0    1384.0    81.0   75074.0  \n",
      "3       68944.0    8407.0  2358.0  147092.0  \n",
      "4       26516.0   31118.0  9930.0  174223.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "file_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos Por Tecnología.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "#Mapeamos los trimestres al último día de cada trimestre\n",
    "trimestre_map = {2: \"06-30\", 1: \"03-31\", 4: \"12-31\", 3: \"09-30\"}\n",
    "print(\"Valores únicos en Trimestre antes de limpieza:\", df['Trimestre'].unique())\n",
    "\n",
    "# Limpiamos la columna 'Trimestre' eliminando caracteres no numéricos\n",
    "df['Trimestre'] = df['Trimestre'].astype(str).str.extract(r'(\\d)').astype(float)\n",
    "\n",
    "# Limpiamos la columna 'Año' eliminando caracteres no numéricos\n",
    "df['Año'] = df['Año'].astype(str).str.extract(r'(\\d{4})')\n",
    "\n",
    "df['Año'] = df['Año'].fillna(0).astype(int)  # Sustituir valores NaN por un valor predeterminado\n",
    "df['Trimestre'] = df['Trimestre'].fillna(0).astype(float)\n",
    "\n",
    "# Convertimos 'Año' a cadena y mapear 'Trimestre' al último día del trimestre\n",
    "if 'Año' in df.columns and 'Trimestre' in df.columns:\n",
    "    df['Año'] = df['Año'].astype(str)\n",
    "    df['Trimestre'] = df['Trimestre'].map(trimestre_map)\n",
    "\n",
    "    # Creamos la columna 'Fecha' combinando 'Año' y 'Trimestre'\n",
    "    df['Fecha'] = pd.to_datetime(df['Año'] + \"-\" + df['Trimestre'], errors='coerce')\n",
    "\n",
    "    # Eliminamos las columnas 'Año' y 'Trimestre'\n",
    "    df.drop(columns=['Año', 'Trimestre'], inplace=True)\n",
    "\n",
    "    # Reordenamos las columnas\n",
    "    cols = ['Fecha'] + [col for col in df.columns if col != 'Fecha']\n",
    "    df = df[cols]\n",
    "else:\n",
    "    print(\"Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\")\n",
    "\n",
    "# Identificamos todas las provincias en el dataset\n",
    "provincias = df['Provincia'].unique()\n",
    "print(\"Provincias en Argentina:\", provincias)\n",
    "print(\"Número total de provincias:\", len(provincias))\n",
    "\n",
    "# Creaamos un diccionario de ID únicos para cada provincia, comenzando desde 1\n",
    "provincia_id_map = {provincia: idx + 1 for idx, provincia in enumerate(provincias)}\n",
    "\n",
    "# Creamos la columna Id_Provincia usando el diccionario\n",
    "df['Id_Provincia'] = df['Provincia'].map(provincia_id_map)\n",
    "\n",
    "# Ordenamos el dataset según el orden de columnas\n",
    "column_order = ['Id_Provincia', 'Provincia', 'Fecha', 'ADSL', 'Cablemodem', 'Fibra óptica', 'Wireless', 'Otros', 'Total']\n",
    "df = df[column_order]\n",
    "\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos Por Tecnología.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL  Accesos_tecnologia_localidad.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Accesos_tecnologia_localidad.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos_tecnologia_localidad.csv\n",
      "      Provincia     Partido   Localidad    Tecnologia Link Indec  Accesos\n",
      "0  BUENOS AIRES  25 de Mayo  25 de Mayo          ADSL    6854100    755.0\n",
      "1  BUENOS AIRES  25 de Mayo  25 de Mayo    CABLEMODEM    6854100   4600.0\n",
      "2  BUENOS AIRES  25 de Mayo  25 de Mayo  FIBRA OPTICA    6854100      2.0\n",
      "3  BUENOS AIRES  25 de Mayo  25 de Mayo     SATELITAL    6854100    742.0\n",
      "4  BUENOS AIRES  25 de Mayo  25 de Mayo      WIRELESS    6854100    727.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7753 entries, 0 to 7752\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Provincia   7753 non-null   object \n",
      " 1   Partido     7753 non-null   object \n",
      " 2   Localidad   7753 non-null   object \n",
      " 3   Tecnologia  7753 non-null   object \n",
      " 4   Link Indec  7753 non-null   object \n",
      " 5   Accesos     7747 non-null   float64\n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 363.6+ KB\n",
      "None\n",
      "        Accesos\n",
      "count    7747.0\n",
      "mean     1491.7\n",
      "std     15201.7\n",
      "min         0.0\n",
      "25%         3.0\n",
      "50%        59.0\n",
      "75%       400.5\n",
      "max   1144781.0\n",
      "Dimensiones del dataframe: (7753, 6)\n",
      "Valores nulos por columna\n",
      "Provincia     0\n",
      "Partido       0\n",
      "Localidad     0\n",
      "Tecnologia    0\n",
      "Link Indec    0\n",
      "Accesos       6\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Provincia    0.0\n",
      "Partido      0.0\n",
      "Localidad    0.0\n",
      "Tecnologia   0.0\n",
      "Link Indec   0.0\n",
      "Accesos      0.1\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos_tecnologia_localidad.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\") \n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un columna id_Provincia , Id_Partido  y Id_Localidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provincias en Argentina: ['BUENOS AIRES' 'CABA' 'CATAMARCA' 'CHACO' 'CHUBUT' 'CORDOBA' 'CORRIENTES'\n",
      " 'ENTRE RIOS' 'FORMOSA' 'JUJUY' 'LA PAMPA' 'LA RIOJA' 'MENDOZA' 'MISIONES'\n",
      " 'NEUQUEN' 'RIO NEGRO' 'SALTA' 'SAN JUAN' 'SAN LUIS' 'SANTA CRUZ'\n",
      " 'SANTA FE' 'SANTIAGO DEL ESTERO' 'TIERRA DEL FUEGO' 'TUCUMAN']\n",
      "Número total de provincias: 24\n",
      "Número total de Partido: 435\n",
      "Número total de localidades: 2793\n",
      "   Id_Provincia     Provincia  Id_Partido     Partido  Id_Localidad  \\\n",
      "0             1  BUENOS AIRES           1  25 de Mayo             1   \n",
      "1             1  BUENOS AIRES           1  25 de Mayo             1   \n",
      "2             1  BUENOS AIRES           1  25 de Mayo             1   \n",
      "3             1  BUENOS AIRES           1  25 de Mayo             1   \n",
      "4             1  BUENOS AIRES           1  25 de Mayo             1   \n",
      "\n",
      "    Localidad    Tecnologia Link Indec  Accesos  \n",
      "0  25 de Mayo          ADSL    6854100    755.0  \n",
      "1  25 de Mayo    CABLEMODEM    6854100   4600.0  \n",
      "2  25 de Mayo  FIBRA OPTICA    6854100      2.0  \n",
      "3  25 de Mayo     SATELITAL    6854100    742.0  \n",
      "4  25 de Mayo      WIRELESS    6854100    727.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrgsi\\AppData\\Local\\Temp\\ipykernel_18828\\2316679060.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Accesos'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos_tecnologia_localidad.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Identificamos todas las provincias en el dataset\n",
    "provincias = df['Provincia'].unique()\n",
    "print(\"Provincias en Argentina:\", provincias)\n",
    "print(\"Número total de provincias:\", len(provincias))\n",
    "\n",
    "# Creamos un diccionario de ID únicos para cada provincia, comenzando desde 1\n",
    "provincia_id_map = {provincia: idx + 1 for idx, provincia in enumerate(provincias)}\n",
    "\n",
    "# Creamos la columna Id_Provincia usando el diccionario\n",
    "df['Id_Provincia'] = df['Provincia'].map(provincia_id_map)\n",
    "\n",
    "\n",
    "# Reemplazamos valores vacíos o espacios en blanco en la columna 'Accesos' con 0 \n",
    "df['Accesos'] = pd.to_numeric(df['Accesos'], errors='coerce') \n",
    "df['Accesos'].fillna(0, inplace=True)  \n",
    "\n",
    "# Identificamos todas los Partido en el dataset\n",
    "partido = df['Partido'].unique()\n",
    "print(\"Número total de Partido:\", len(partido))\n",
    "\n",
    "# Creamos un diccionario único para cada partido comenzando en 1\n",
    "partido_id_map = {partido: idx + 1 for idx, partido in enumerate(partido)}\n",
    "\n",
    "# Creamos la columna Id_Localidad usando el diccionario\n",
    "df['Id_Partido'] = df['Partido'].map(partido_id_map)\n",
    "\n",
    "\n",
    "# Identificamos todas las localidades en el dataset\n",
    "localidades = df['Localidad'].unique()\n",
    "print(\"Número total de localidades:\", len(localidades))\n",
    "\n",
    "# Creamos un diccionario único para cada localidad comenzando en 1\n",
    "localidad_id_map = {localidad: idx + 1 for idx, localidad in enumerate(localidades)}\n",
    "\n",
    "# Creamos la columna Id_Localidad usando el diccionario\n",
    "df['Id_Localidad'] = df['Localidad'].map(localidad_id_map)\n",
    "\n",
    "\n",
    "# Ordenamos el dataset según el orden de columnas\n",
    "column_order = ['Id_Provincia','Provincia', 'Id_Partido','Partido','Id_Localidad','Localidad' ,'Tecnologia','Link Indec','Accesos']\n",
    "df = df[column_order]\n",
    "\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Accesos_tecnologia_localidad.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Dial-BAf.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Dial-BAf.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Dial-BAf.csv\n",
      "    Año  Trimestre        Provincia  Banda ancha fija  Dial up    Total\n",
      "0  2024          2     Buenos Aires           4983480   5900.0  4989380\n",
      "1  2024          2  Capital Federal           1461549   2050.0  1463599\n",
      "2  2024          2        Catamarca             75073      1.0    75074\n",
      "3  2024          2            Chaco            147087      5.0   147092\n",
      "4  2024          2           Chubut            173366    857.0   174223\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1992 entries, 0 to 1991\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Año               1992 non-null   int64  \n",
      " 1   Trimestre         1992 non-null   int64  \n",
      " 2   Provincia         1992 non-null   object \n",
      " 3   Banda ancha fija  1992 non-null   int64  \n",
      " 4   Dial up           1988 non-null   float64\n",
      " 5   Total             1992 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 93.5+ KB\n",
      "None\n",
      "         Año  Trimestre  Banda ancha fija  Dial up     Total\n",
      "count 1992.0     1992.0            1992.0   1988.0    1992.0\n",
      "mean  2018.7        2.5          365054.2    902.1  365954.5\n",
      "std      3.0        1.1          785885.2   2281.7  787608.8\n",
      "min   2014.0        1.0           12193.0      0.0   12557.0\n",
      "25%   2016.0        1.0           61834.0      5.0   62236.0\n",
      "50%   2019.0        2.0          112315.0    137.0  113663.0\n",
      "75%   2021.0        3.0          195471.0    615.0  195471.0\n",
      "max   2024.0        4.0         5038657.0  15229.0 5044557.0\n",
      "Dimensiones del dataframe: (1992, 6)\n",
      "Valores nulos por columna\n",
      "Año                 0\n",
      "Trimestre           0\n",
      "Provincia           0\n",
      "Banda ancha fija    0\n",
      "Dial up             4\n",
      "Total               0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Año                0.0\n",
      "Trimestre          0.0\n",
      "Provincia          0.0\n",
      "Banda ancha fija   0.0\n",
      "Dial up            0.0\n",
      "Total              0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Dial-BAf.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\") \n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Reemplazamos valores faltantes con 0 o corregir errores\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el formato de fecha para que sea un formato mas compatible con Python uniendo la columna fecha con la columna trimestre, ademas se crea la columna Id_Provincia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provincias en Argentina: ['Buenos Aires' 'Capital Federal' 'Catamarca' 'Chaco' 'Chubut' 'Córdoba'\n",
      " 'Corrientes' 'Entre Ríos' 'Formosa' 'Jujuy' 'La Pampa' 'La Rioja'\n",
      " 'Mendoza' 'Misiones' 'Neuquén' 'Río Negro' 'Salta' 'San Juan' 'San Luis'\n",
      " 'Santa Cruz' 'Santa Fe' 'Santiago Del Estero' 'Tierra Del Fuego'\n",
      " 'Tucumán']\n",
      "Número total de provincias: 24\n",
      "   Id_Provincia        Provincia      Fecha  Banda ancha fija  Dial up  \\\n",
      "0             1     Buenos Aires 2024-06-30           4983480   5900.0   \n",
      "1             2  Capital Federal 2024-06-30           1461549   2050.0   \n",
      "2             3        Catamarca 2024-06-30             75073      1.0   \n",
      "3             4            Chaco 2024-06-30            147087      5.0   \n",
      "4             5           Chubut 2024-06-30            173366    857.0   \n",
      "\n",
      "     Total  \n",
      "0  4989380  \n",
      "1  1463599  \n",
      "2    75074  \n",
      "3   147092  \n",
      "4   174223  \n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Dial-BAf.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Mapeamos los trimestres al último día de cada trimestre\n",
    "trimestre_map = {1: \"03-31\", 2: \"06-30\", 3: \"09-30\", 4: \"12-31\"}\n",
    "\n",
    "# Convertimos 'Año' a cadena y mapear 'Trimestre' al último día del trimestre\n",
    "if 'Año' in df.columns and 'Trimestre' in df.columns:\n",
    "    df['Año'] = df['Año'].astype(str)\n",
    "    df['Trimestre'] = df['Trimestre'].map(trimestre_map)\n",
    "\n",
    "    # Creamos la columna 'Fecha' combinando 'Año' y 'Trimestre'\n",
    "    df['Fecha'] = pd.to_datetime(df['Año'] + \"-\" + df['Trimestre'])\n",
    "\n",
    "    # Borramos  las columnas 'Año' y 'Trimestre'\n",
    "    df.drop(columns=['Año', 'Trimestre'], inplace=True)\n",
    "\n",
    "    # Reordenamos las columnas \n",
    "    cols = ['Fecha'] + [col for col in df.columns if col != 'Fecha']\n",
    "    df = df[cols]\n",
    "else:\n",
    "    print(\"Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\")\n",
    "\n",
    "\n",
    "# Identificamos todas las provincias en el dataset\n",
    "provincias = df['Provincia'].unique()\n",
    "print(\"Provincias en Argentina:\", provincias)\n",
    "print(\"Número total de provincias:\", len(provincias))\n",
    "\n",
    "# Creamos un diccionario de ID únicos para cada provincia, comenzando desde 1\n",
    "provincia_id_map = {provincia: idx + 1 for idx, provincia in enumerate(provincias)}\n",
    "\n",
    "# Creamos la columna Id_Provincia usando el diccionario\n",
    "df['Id_Provincia'] = df['Provincia'].map(provincia_id_map)\n",
    "\n",
    "# Ordenamos el dataset según el orden de columnas\n",
    "column_order = ['Id_Provincia','Provincia', 'Fecha','Banda ancha fija','Dial up','Total']\n",
    "df = df[column_order]\n",
    "\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Dial-BAf.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Ingresos .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Ingresos .csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Ingresos .csv\n",
      "    Año  Trimestre  Ingresos (miles de pesos)        Periodo\n",
      "0  2024          2                442032166.7   Abr-Jun 2024\n",
      "1  2024          1                346198986.1   Ene-Mar 2024\n",
      "2  2023          4                167376014.8   Oct-Dic 2023\n",
      "3  2023          3                133106593.4  Jul-Sept 2023\n",
      "4  2023          2                118060280.3   Jun-Mar 2023\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 4 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Año                        42 non-null     int64  \n",
      " 1   Trimestre                  42 non-null     int64  \n",
      " 2   Ingresos (miles de pesos)  42 non-null     float64\n",
      " 3   Periodo                    42 non-null     object \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 1.4+ KB\n",
      "None\n",
      "         Año  Trimestre  Ingresos (miles de pesos)\n",
      "count   42.0       42.0                       42.0\n",
      "mean  2019.0        2.5                 50016480.8\n",
      "std      3.7        1.1                 87102080.5\n",
      "min   2014.0        1.0                  2984054.2\n",
      "25%   2016.0        1.2                  7055326.3\n",
      "50%   2019.0        2.0                 20475265.7\n",
      "75%   2021.0        3.0                 44850901.4\n",
      "max   2033.0        4.0                442032166.7\n",
      "Dimensiones del dataframe: (42, 4)\n",
      "Valores nulos por columna\n",
      "Año                          0\n",
      "Trimestre                    0\n",
      "Ingresos (miles de pesos)    0\n",
      "Periodo                      0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Año                         0.0\n",
      "Trimestre                   0.0\n",
      "Ingresos (miles de pesos)   0.0\n",
      "Periodo                     0.0\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Ingresos .csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\")  \n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el formato de fecha para que sea un formato más compatible con Python uniendo la columna fecha con la columna trimestre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Fecha  Ingresos (miles de pesos)  Año_Temporal  Ganancia Anual (%)\n",
      "0  2024-06-30                442032166.7          2024                88.3\n",
      "1  2024-03-31                346198986.1          2024                88.3\n",
      "2  2023-12-31                167376014.8          2023                66.0\n",
      "3  2023-09-30                133106593.4          2023                66.0\n",
      "4  2023-06-30                118060280.3          2023                66.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Ingresos .csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Convertir 'Año_Temporal' a tipo entero si no lo está\n",
    "df['Año_Temporal'] = df['Año_Temporal'].astype(int)\n",
    "\n",
    "# Agrupamos por año y calculamos el ingreso anual total\n",
    "ingresos_anuales = df.groupby('Año_Temporal')['Ingresos (miles de pesos)'].sum().reset_index()\n",
    "ingresos_anuales.rename(columns={'Ingresos (miles de pesos)': 'Ingresos Anuales'}, inplace=True)\n",
    "\n",
    "# Calculamos el porcentaje de cambio respecto al año anterior\n",
    "ingresos_anuales['Ganancia Anual (%)'] = ingresos_anuales['Ingresos Anuales'].pct_change() * 100\n",
    "\n",
    "# Redondear el porcentaje a dos decimales\n",
    "ingresos_anuales['Ganancia Anual (%)'] = ingresos_anuales['Ganancia Anual (%)'].round(2)\n",
    "\n",
    "# Unimos los ingresos anuales calculados al DataFrame original\n",
    "df = df.merge(ingresos_anuales[['Año_Temporal', 'Ganancia Anual (%)']], on='Año_Temporal', how='left')\n",
    "\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Ingresos_Calculado.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Penetracion-hogares.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Penetracion-hogares.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetracion-hogares.csv\n",
      "    Año  Trimestre        Provincia  Accesos por cada 100 hogares\n",
      "0  2024          2     Buenos Aires                          79.8\n",
      "1  2024          2  Capital Federal                         116.4\n",
      "2  2024          2        Catamarca                          68.8\n",
      "3  2024          2            Chaco                          44.1\n",
      "4  2024          2           Chubut                          86.3\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Año                           1000 non-null   int64  \n",
      " 1   Trimestre                     1000 non-null   int64  \n",
      " 2   Provincia                     1000 non-null   object \n",
      " 3   Accesos por cada 100 hogares  1000 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 31.4+ KB\n",
      "None\n",
      "         Año  Trimestre  Accesos por cada 100 hogares\n",
      "count 1000.0     1000.0                        1000.0\n",
      "mean  2018.8        2.5                          52.8\n",
      "std      3.0        1.1                          24.1\n",
      "min   2014.0        1.0                           9.5\n",
      "25%   2016.0        1.0                          34.0\n",
      "50%   2019.0        2.0                          50.1\n",
      "75%   2021.0        3.0                          67.0\n",
      "max   2024.0        4.0                         124.1\n",
      "Dimensiones del dataframe: (1000, 4)\n",
      "Valores nulos por columna\n",
      "Año                             0\n",
      "Trimestre                       0\n",
      "Provincia                       0\n",
      "Accesos por cada 100 hogares    0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Año                            0.0\n",
      "Trimestre                      0.0\n",
      "Provincia                      0.0\n",
      "Accesos por cada 100 hogares   0.0\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargamos la carpeta con el archivo .CSV \n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetracion-hogares.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\") \n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el formato de fecha para que sea un formato más compatible con Python uniendo la columna fecha con la columna trimestre y se crea la columna Id_Provincias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provincias en Argentina: ['Buenos Aires' 'Capital Federal' 'Catamarca' 'Chaco' 'Chubut' 'Córdoba'\n",
      " 'Corrientes' 'Entre Ríos' 'Formosa' 'Jujuy' 'La Pampa' 'La Rioja'\n",
      " 'Mendoza' 'Misiones' 'Neuquén' 'Río Negro' 'Salta' 'San Juan' 'San Luis'\n",
      " 'Santa Cruz' 'Santa Fe' 'Santiago Del Estero' 'Tierra Del Fuego'\n",
      " 'Tucumán']\n",
      "Número total de provincias: 24\n",
      "   Id_Provincia        Provincia      Fecha  Accesos por cada 100 hogares\n",
      "0             1     Buenos Aires 2024-06-30                          79.8\n",
      "1             2  Capital Federal 2024-06-30                         116.4\n",
      "2             3        Catamarca 2024-06-30                          68.8\n",
      "3             4            Chaco 2024-06-30                          44.1\n",
      "4             5           Chubut 2024-06-30                          86.3\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetracion-hogares.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Mapeamos los trimestres al último día de cada trimestre\n",
    "trimestre_map = {1: \"03-31\", 2: \"06-30\", 3: \"09-30\", 4: \"12-31\"}\n",
    "\n",
    "# Convertimos 'Año' a cadena y mapear 'Trimestre' al último día del trimestre\n",
    "if 'Año' in df.columns and 'Trimestre' in df.columns:\n",
    "    df['Año'] = df['Año'].astype(str)\n",
    "    df['Trimestre'] = df['Trimestre'].map(trimestre_map)\n",
    "\n",
    "    # Creamos la columna 'Fecha' combinando 'Año' y 'Trimestre'\n",
    "    df['Fecha'] = pd.to_datetime(df['Año'] + \"-\" + df['Trimestre'])\n",
    "\n",
    "    # Borramos  las columnas 'Año' y 'Trimestre'\n",
    "    df.drop(columns=['Año', 'Trimestre'], inplace=True)\n",
    "\n",
    "    # Reordenamos las columnas \n",
    "    cols = ['Fecha'] + [col for col in df.columns if col != 'Fecha']\n",
    "    df = df[cols]\n",
    "else:\n",
    "    print(\"Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\")\n",
    "# Identificamos todas las provincias en el dataset\n",
    "provincias = df['Provincia'].unique()\n",
    "print(\"Provincias en Argentina:\", provincias)\n",
    "print(\"Número total de provincias:\", len(provincias))\n",
    "\n",
    "# Creamos un diccionario de ID únicos para cada provincia, comenzando desde 1\n",
    "provincia_id_map = {provincia: idx + 1 for idx, provincia in enumerate(provincias)}\n",
    "\n",
    "# Creamos la columna Id_Provincia usando el diccionario\n",
    "df['Id_Provincia'] = df['Provincia'].map(provincia_id_map)\n",
    "\n",
    "# Ordenamos el dataset según el orden de columnas\n",
    "column_order = ['Id_Provincia','Provincia','Fecha' ,'Accesos por cada 100 hogares']\n",
    "df = df[column_order]\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetracion-hogares.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Penetración-poblacion.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Penetración-poblacion.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetración-poblacion.csv\n",
      "    Año  Trimestre        Provincia  Accesos por cada 100 hab\n",
      "0  2024          2     Buenos Aires                      27.4\n",
      "1  2024          2  Capital Federal                      47.4\n",
      "2  2024          2        Catamarca                      17.5\n",
      "3  2024          2            Chaco                      11.8\n",
      "4  2024          2           Chubut                      26.5\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Año                       1000 non-null   int64  \n",
      " 1   Trimestre                 1000 non-null   int64  \n",
      " 2   Provincia                 1000 non-null   object \n",
      " 3   Accesos por cada 100 hab  1000 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 31.4+ KB\n",
      "None\n",
      "         Año  Trimestre  Accesos por cada 100 hab\n",
      "count 1000.0     1000.0                    1000.0\n",
      "mean  2018.8        2.5                      15.7\n",
      "std      3.0        1.1                       9.2\n",
      "min   2014.0        1.0                       2.7\n",
      "25%   2016.0        1.0                       9.0\n",
      "50%   2019.0        2.0                      13.7\n",
      "75%   2021.0        3.0                      20.3\n",
      "max   2024.0        4.0                      52.2\n",
      "Dimensiones del dataframe: (1000, 4)\n",
      "Valores nulos por columna\n",
      "Año                         0\n",
      "Trimestre                   0\n",
      "Provincia                   0\n",
      "Accesos por cada 100 hab    0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Año                        0.0\n",
      "Trimestre                  0.0\n",
      "Provincia                  0.0\n",
      "Accesos por cada 100 hab   0.0\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetración-poblacion.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\")  \n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el formato de fecha para que sea un formato mas compatible con Python uniendo la columna fecha con la columna trimestre , ademas se crea la columna Id_Provincia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provincias en Argentina: ['Buenos Aires' 'Capital Federal' 'Catamarca' 'Chaco' 'Chubut' 'Córdoba'\n",
      " 'Corrientes' 'Entre Ríos' 'Formosa' 'Jujuy' 'La Pampa' 'La Rioja'\n",
      " 'Mendoza' 'Misiones' 'Neuquén' 'Río Negro' 'Salta' 'San Juan' 'San Luis'\n",
      " 'Santa Cruz' 'Santa Fe' 'Santiago Del Estero' 'Tierra Del Fuego'\n",
      " 'Tucumán']\n",
      "Número total de provincias: 24\n",
      "   Id_Provincia        Provincia      Fecha  Accesos por cada 100 hab\n",
      "0             1     Buenos Aires 2024-06-30                      27.4\n",
      "1             2  Capital Federal 2024-06-30                      47.4\n",
      "2             3        Catamarca 2024-06-30                      17.5\n",
      "3             4            Chaco 2024-06-30                      11.8\n",
      "4             5           Chubut 2024-06-30                      26.5\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetración-poblacion.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Mapeamos los trimestres al último día de cada trimestre\n",
    "trimestre_map = {1: \"03-31\", 2: \"06-30\", 3: \"09-30\", 4: \"12-31\"}\n",
    "\n",
    "# Convertimos 'Año' a cadena y mapear 'Trimestre' al último día del trimestre\n",
    "if 'Año' in df.columns and 'Trimestre' in df.columns:\n",
    "    df['Año'] = df['Año'].astype(str)\n",
    "    df['Trimestre'] = df['Trimestre'].map(trimestre_map)\n",
    "\n",
    "    # Creamos la columna 'Fecha' combinando 'Año' y 'Trimestre'\n",
    "    df['Fecha'] = pd.to_datetime(df['Año'] + \"-\" + df['Trimestre'])\n",
    "\n",
    "    # Borramos  las columnas 'Año' y 'Trimestre'\n",
    "    df.drop(columns=['Año', 'Trimestre'], inplace=True)\n",
    "\n",
    "    # Reordenamos las columnas \n",
    "    cols = ['Fecha'] + [col for col in df.columns if col != 'Fecha']\n",
    "    df = df[cols]\n",
    "else:\n",
    "    print(\"Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\")\n",
    "\n",
    "\n",
    "# Identificamos todas las provincias en el dataset\n",
    "provincias = df['Provincia'].unique()\n",
    "print(\"Provincias en Argentina:\", provincias)\n",
    "print(\"Número total de provincias:\", len(provincias))\n",
    "\n",
    "# Creamos un diccionario de ID únicos para cada provincia, comenzando desde 1\n",
    "provincia_id_map = {provincia: idx + 1 for idx, provincia in enumerate(provincias)}\n",
    "\n",
    "# Creamos la columna Id_Provincia usando el diccionario\n",
    "df['Id_Provincia'] = df['Provincia'].map(provincia_id_map)\n",
    "\n",
    "# Ordenamos el dataset según el orden de columnas\n",
    "column_order = ['Id_Provincia','Provincia', 'Fecha','Accesos por cada 100 hab']\n",
    "df = df[column_order]\n",
    "\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetración-poblacion.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Penetracion-totales.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Penetracion-totales.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetracion-totales.csv\n",
      "    Año  Trimestre  Accesos por cada 100 hogares  Accesos por cada 100 hab  \\\n",
      "0  2024          2                          78.1                      24.6   \n",
      "1  2024          1                          78.9                      24.8   \n",
      "2  2023          4                          78.6                      24.7   \n",
      "3  2023          3                          77.8                      24.4   \n",
      "4  2023          2                          77.0                      24.1   \n",
      "\n",
      "         Periodo  \n",
      "0   Abr-Jun 2024  \n",
      "1   Ene-Mar 2024  \n",
      "2   Oct-Dic 2023  \n",
      "3  Jul-Sept 2023  \n",
      "4   Abr-Jun 2023  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 5 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Año                           42 non-null     int64  \n",
      " 1   Trimestre                     42 non-null     int64  \n",
      " 2   Accesos por cada 100 hogares  42 non-null     float64\n",
      " 3   Accesos por cada 100 hab      42 non-null     float64\n",
      " 4   Periodo                       42 non-null     object \n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 1.8+ KB\n",
      "None\n",
      "         Año  Trimestre  Accesos por cada 100 hogares  \\\n",
      "count   42.0       42.0                          42.0   \n",
      "mean  2018.8        2.5                          63.2   \n",
      "std      3.1        1.1                          10.0   \n",
      "min   2014.0        1.0                          49.5   \n",
      "25%   2016.0        1.2                          53.8   \n",
      "50%   2019.0        2.0                          62.7   \n",
      "75%   2021.0        3.0                          72.5   \n",
      "max   2024.0        4.0                          78.9   \n",
      "\n",
      "       Accesos por cada 100 hab  \n",
      "count                      42.0  \n",
      "mean                       19.6  \n",
      "std                         3.3  \n",
      "min                        15.1  \n",
      "25%                        16.5  \n",
      "50%                        19.4  \n",
      "75%                        22.6  \n",
      "max                        24.8  \n",
      "Dimensiones del dataframe: (42, 5)\n",
      "Valores nulos por columna\n",
      "Año                             0\n",
      "Trimestre                       0\n",
      "Accesos por cada 100 hogares    0\n",
      "Accesos por cada 100 hab        0\n",
      "Periodo                         0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Año                            0.0\n",
      "Trimestre                      0.0\n",
      "Accesos por cada 100 hogares   0.0\n",
      "Accesos por cada 100 hab       0.0\n",
      "Periodo                        0.0\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetracion-totales.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\") \n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el formato de fecha para que sea un formato más compatible con Python uniendo la columna fecha con la columna trimestre y se bora la columna Periodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Fecha  Accesos por cada 100 hogares  Accesos por cada 100 hab\n",
      "0 2024-06-30                          78.1                      24.6\n",
      "1 2024-03-31                          78.9                      24.8\n",
      "2 2023-12-31                          78.6                      24.7\n",
      "3 2023-09-30                          77.8                      24.4\n",
      "4 2023-06-30                          77.0                      24.1\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetracion-totales.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Mapeamos los trimestres al último día de cada trimestre\n",
    "trimestre_map = {1: \"03-31\", 2: \"06-30\", 3: \"09-30\", 4: \"12-31\"}\n",
    "\n",
    "# Convertimos 'Año' a cadena y mapear 'Trimestre' al último día del trimestre\n",
    "if 'Año' in df.columns and 'Trimestre' in df.columns:\n",
    "    df['Año'] = df['Año'].astype(str)\n",
    "    df['Trimestre'] = df['Trimestre'].map(trimestre_map)\n",
    "\n",
    "    # Creamos la columna 'Fecha' combinando 'Año' y 'Trimestre'\n",
    "    df['Fecha'] = pd.to_datetime(df['Año'] + \"-\" + df['Trimestre'])\n",
    "\n",
    "    # Borramos  las columnas 'Año' y 'Trimestre'\n",
    "    df.drop(columns=['Año', 'Trimestre'], inplace=True)\n",
    "\n",
    "    # Reordenamos las columnas \n",
    "    cols = ['Fecha'] + [col for col in df.columns if col != 'Fecha']\n",
    "    df = df[cols]\n",
    "else:\n",
    "    print(\"Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\")\n",
    "\n",
    "    # Eliminamos columa Periodo\n",
    "df.drop(columns=['Periodo'], inplace=True)\n",
    "\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Penetracion-totales.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Totales Accesos por rango.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Totales Accesos por rango.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Accesos por rango.csv\n",
      "    Año  Trimestre  Hasta 512 kbps  Entre 512 Kbps y 1 Mbps  \\\n",
      "0  2024          2           28151                    67024   \n",
      "1  2024          1           28801                    69355   \n",
      "2  2023          4           29708                    71742   \n",
      "3  2023          3           30274                    80609   \n",
      "4  2023          2           30827                    79405   \n",
      "\n",
      "   Entre 1 Mbps y 6 Mbps  Entre 6 Mbps y 10 Mbps  Entre 10 Mbps y 20 Mbps  \\\n",
      "0                 840200                  911374                   662649   \n",
      "1                 866152                  950930                   672155   \n",
      "2                 900253                  978108                   697232   \n",
      "3                 945608                  998725                   720084   \n",
      "4                 963510                 1028250                   734125   \n",
      "\n",
      "   Entre 20 Mbps y 30 Mbps  Más de 30 Mbps   OTROS     Total  \n",
      "0                   348253         8357088  341368  11556107  \n",
      "1                   353896         8363694  328173  11633156  \n",
      "2                   350290         8224736  295592  11547661  \n",
      "3                   350918         8003269  277421  11406908  \n",
      "4                   364730         7775095  275955  11251897  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype\n",
      "---  ------                   --------------  -----\n",
      " 0   Año                      42 non-null     int64\n",
      " 1   Trimestre                42 non-null     int64\n",
      " 2   Hasta 512 kbps           42 non-null     int64\n",
      " 3   Entre 512 Kbps y 1 Mbps  42 non-null     int64\n",
      " 4   Entre 1 Mbps y 6 Mbps    42 non-null     int64\n",
      " 5   Entre 6 Mbps y 10 Mbps   42 non-null     int64\n",
      " 6   Entre 10 Mbps y 20 Mbps  42 non-null     int64\n",
      " 7   Entre 20 Mbps y 30 Mbps  42 non-null     int64\n",
      " 8   Más de 30 Mbps           42 non-null     int64\n",
      " 9   OTROS                    42 non-null     int64\n",
      " 10  Total                    42 non-null     int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 3.7 KB\n",
      "None\n",
      "         Año  Trimestre  Hasta 512 kbps  Entre 512 Kbps y 1 Mbps  \\\n",
      "count   42.0       42.0            42.0                     42.0   \n",
      "mean  2018.8        2.5         46756.6                 215615.3   \n",
      "std      3.1        1.1         48923.0                 192134.7   \n",
      "min   2014.0        1.0          5675.0                  28521.0   \n",
      "25%   2016.0        1.2         29027.8                  69951.8   \n",
      "50%   2019.0        2.0         34960.0                 150273.0   \n",
      "75%   2021.0        3.0         41057.5                 279159.2   \n",
      "max   2024.0        4.0        241713.0                 687619.0   \n",
      "\n",
      "       Entre 1 Mbps y 6 Mbps  Entre 6 Mbps y 10 Mbps  Entre 10 Mbps y 20 Mbps  \\\n",
      "count                   42.0                    42.0                     42.0   \n",
      "mean               3176364.8                915481.9                 884427.6   \n",
      "std                1552136.4                229375.8                 451590.0   \n",
      "min                 840200.0                289182.0                 101127.0   \n",
      "25%                1692723.8                862345.2                 677435.5   \n",
      "50%                3313002.5                978762.0                 792972.5   \n",
      "75%                4780395.5               1058517.5                1022656.5   \n",
      "max                5153437.0               1245333.0                2068087.0   \n",
      "\n",
      "       Entre 20 Mbps y 30 Mbps  Más de 30 Mbps    OTROS      Total  \n",
      "count                     42.0            42.0     42.0       42.0  \n",
      "mean                  478365.6       2909772.3 154081.1  8780865.1  \n",
      "std                   433434.3       3138714.7 132454.0  1772654.7  \n",
      "min                      345.0         11595.0      0.0  6272846.0  \n",
      "25%                   135803.5         32914.0      0.0  7151638.0  \n",
      "50%                   361249.5       1408279.0 176235.5  8720658.0  \n",
      "75%                   592545.0       5761285.0 242214.0 10388730.8  \n",
      "max                  1688748.0       8363694.0 414754.0 11633156.0  \n",
      "Dimensiones del dataframe: (42, 11)\n",
      "Valores nulos por columna\n",
      "Año                        0\n",
      "Trimestre                  0\n",
      "Hasta 512 kbps             0\n",
      "Entre 512 Kbps y 1 Mbps    0\n",
      "Entre 1 Mbps y 6 Mbps      0\n",
      "Entre 6 Mbps y 10 Mbps     0\n",
      "Entre 10 Mbps y 20 Mbps    0\n",
      "Entre 20 Mbps y 30 Mbps    0\n",
      "Más de 30 Mbps             0\n",
      "OTROS                      0\n",
      "Total                      0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Año                       0.0\n",
      "Trimestre                 0.0\n",
      "Hasta 512 kbps            0.0\n",
      "Entre 512 Kbps y 1 Mbps   0.0\n",
      "Entre 1 Mbps y 6 Mbps     0.0\n",
      "Entre 6 Mbps y 10 Mbps    0.0\n",
      "Entre 10 Mbps y 20 Mbps   0.0\n",
      "Entre 20 Mbps y 30 Mbps   0.0\n",
      "Más de 30 Mbps            0.0\n",
      "OTROS                     0.0\n",
      "Total                     0.0\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Accesos por rango.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\")\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el formato de fecha para que sea un formato más compatible con Python uniendo la columna fecha con la columna trimestre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Fecha  Hasta 512 kbps  Entre 512 Kbps y 1 Mbps  Entre 1 Mbps y 6 Mbps  \\\n",
      "0 2024-06-30           28151                    67024                 840200   \n",
      "1 2024-03-31           28801                    69355                 866152   \n",
      "2 2023-12-31           29708                    71742                 900253   \n",
      "3 2023-09-30           30274                    80609                 945608   \n",
      "4 2023-06-30           30827                    79405                 963510   \n",
      "\n",
      "   Entre 6 Mbps y 10 Mbps  Entre 10 Mbps y 20 Mbps  Entre 20 Mbps y 30 Mbps  \\\n",
      "0                  911374                   662649                   348253   \n",
      "1                  950930                   672155                   353896   \n",
      "2                  978108                   697232                   350290   \n",
      "3                  998725                   720084                   350918   \n",
      "4                 1028250                   734125                   364730   \n",
      "\n",
      "   Más de 30 Mbps   OTROS     Total  \n",
      "0         8357088  341368  11556107  \n",
      "1         8363694  328173  11633156  \n",
      "2         8224736  295592  11547661  \n",
      "3         8003269  277421  11406908  \n",
      "4         7775095  275955  11251897  \n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Accesos por rango.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Mapeamos los trimestres al último día de cada trimestre\n",
    "trimestre_map = {1: \"03-31\", 2: \"06-30\", 3: \"09-30\", 4: \"12-31\"}\n",
    "\n",
    "# Convertimos 'Año' a cadena y mapear 'Trimestre' al último día del trimestre\n",
    "if 'Año' in df.columns and 'Trimestre' in df.columns:\n",
    "    df['Año'] = df['Año'].astype(str)\n",
    "    df['Trimestre'] = df['Trimestre'].map(trimestre_map)\n",
    "\n",
    "    # Creamos la columna 'Fecha' combinando 'Año' y 'Trimestre'\n",
    "    df['Fecha'] = pd.to_datetime(df['Año'] + \"-\" + df['Trimestre'])\n",
    "\n",
    "    # Borramos  las columnas 'Año' y 'Trimestre'\n",
    "    df.drop(columns=['Año', 'Trimestre'], inplace=True)\n",
    "\n",
    "    # Reordenamos las columnas \n",
    "    cols = ['Fecha'] + [col for col in df.columns if col != 'Fecha']\n",
    "    df = df[cols]\n",
    "else:\n",
    "    print(\"Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\")\n",
    "\n",
    "\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Accesos por rango.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Totales Accesos Por Tecnología.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Accesos Por Tecnología.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Accesos Por Tecnología.csv\n",
      "    Año  Trimestre     ADSL  Cablemodem  Fibra óptica  Wireless   Otros  \\\n",
      "0  2024          2   733491     5867504       4169958    593197  191957   \n",
      "1  2024          1   774475     5986957       4015101    598682  257941   \n",
      "2  2023          4   836390     6022532       3908183    585760  194796   \n",
      "3  2023          3   897895     6018832       3708718    581436  200027   \n",
      "4  2023          2  1006509     5997149       3463988    581823  202428   \n",
      "\n",
      "      Total        Periodo  \n",
      "0  11556107   Abr-Jun 2024  \n",
      "1  11633156   Ene-Mar 2024  \n",
      "2  11547661   Oct-Dic 2023  \n",
      "3  11406908  Jul-Sept 2023  \n",
      "4  11251897   Abr-Jun 2023  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Año           42 non-null     int64 \n",
      " 1   Trimestre     42 non-null     int64 \n",
      " 2   ADSL          42 non-null     int64 \n",
      " 3   Cablemodem    42 non-null     int64 \n",
      " 4   Fibra óptica  42 non-null     int64 \n",
      " 5   Wireless      42 non-null     int64 \n",
      " 6   Otros         42 non-null     int64 \n",
      " 7   Total         42 non-null     int64 \n",
      " 8   Periodo       42 non-null     object\n",
      "dtypes: int64(8), object(1)\n",
      "memory usage: 3.1+ KB\n",
      "None\n",
      "         Año  Trimestre      ADSL  Cablemodem  Fibra óptica  Wireless  \\\n",
      "count   42.0       42.0      42.0        42.0          42.0      42.0   \n",
      "mean  2018.8        2.5 2694843.9   4433906.0     1224693.6  304293.2   \n",
      "std      3.1        1.1 1094346.6   1319783.0     1321136.0  203202.4   \n",
      "min   2014.0        1.0  733491.0   2407330.0      139187.0   70749.0   \n",
      "25%   2016.0        1.2 1730869.0   3146291.8      171941.0   85390.5   \n",
      "50%   2019.0        2.0 3061623.0   4535507.0      698946.5  292223.0   \n",
      "75%   2021.0        3.0 3713297.5   5857192.2     1945689.0  515434.0   \n",
      "max   2024.0        4.0 3803024.0   6073426.0     4169958.0  598682.0   \n",
      "\n",
      "         Otros      Total  \n",
      "count     42.0       42.0  \n",
      "mean  158186.1  8815922.7  \n",
      "std    82363.5  1733188.8  \n",
      "min    54300.0  6398398.0  \n",
      "25%    70430.0  7218130.8  \n",
      "50%   185221.0  8720658.0  \n",
      "75%   244069.5 10388730.8  \n",
      "max   265328.0 11633156.0  \n",
      "Dimensiones del dataframe: (42, 9)\n",
      "Valores nulos por columna\n",
      "Año             0\n",
      "Trimestre       0\n",
      "ADSL            0\n",
      "Cablemodem      0\n",
      "Fibra óptica    0\n",
      "Wireless        0\n",
      "Otros           0\n",
      "Total           0\n",
      "Periodo         0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Año            0.0\n",
      "Trimestre      0.0\n",
      "ADSL           0.0\n",
      "Cablemodem     0.0\n",
      "Fibra óptica   0.0\n",
      "Wireless       0.0\n",
      "Otros          0.0\n",
      "Total          0.0\n",
      "Periodo        0.0\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Accesos Por Tecnología.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\")  \n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el formato de fecha para que sea un formato más compatible con Python uniendo la columna fecha con la columna trimestre y se borra la columna Periodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Fecha     ADSL  Cablemodem  Fibra óptica  Wireless   Otros     Total\n",
      "0 2024-06-30   733491     5867504       4169958    593197  191957  11556107\n",
      "1 2024-03-31   774475     5986957       4015101    598682  257941  11633156\n",
      "2 2023-12-31   836390     6022532       3908183    585760  194796  11547661\n",
      "3 2023-09-30   897895     6018832       3708718    581436  200027  11406908\n",
      "4 2023-06-30  1006509     5997149       3463988    581823  202428  11251897\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Accesos Por Tecnología.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Mapeamos los trimestres al último día de cada trimestre\n",
    "trimestre_map = {1: \"03-31\", 2: \"06-30\", 3: \"09-30\", 4: \"12-31\"}\n",
    "\n",
    "# Convertimos 'Año' a cadena y mapear 'Trimestre' al último día del trimestre\n",
    "if 'Año' in df.columns and 'Trimestre' in df.columns:\n",
    "    df['Año'] = df['Año'].astype(str)\n",
    "    df['Trimestre'] = df['Trimestre'].map(trimestre_map)\n",
    "\n",
    "    # Creamos la columna 'Fecha' combinando 'Año' y 'Trimestre'\n",
    "    df['Fecha'] = pd.to_datetime(df['Año'] + \"-\" + df['Trimestre'])\n",
    "\n",
    "    # Borramos  las columnas 'Año' y 'Trimestre'\n",
    "    df.drop(columns=['Año', 'Trimestre'], inplace=True)\n",
    "\n",
    "    # Reordenamos las columnas \n",
    "    cols = ['Fecha'] + [col for col in df.columns if col != 'Fecha']\n",
    "    df = df[cols]\n",
    "else:\n",
    "    print(\"Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\")\n",
    "\n",
    "# Eliminamos columnas poco relevantes\n",
    "df.drop(columns=['Periodo'], inplace=True)\n",
    "\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Accesos Por Tecnología.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Totales Dial-BAf.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Totales Dial-BAf.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Dial-BAf.csv\n",
      "    Año  Trimestre  Banda ancha fija  Dial up     Total        Periodo\n",
      "0  2024          2          11544314    11793  11556107   Abr-Jun 2024\n",
      "1  2024          1          11621363    11793  11633156   Ene-Mar 2024\n",
      "2  2023          4          11535868    11793  11547661   Oct-Dic 2023\n",
      "3  2023          3          11395115    11793  11406908  Jul-Sept 2023\n",
      "4  2023          2          11239781    12116  11251897   Abr-Jun 2023\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Año               42 non-null     int64 \n",
      " 1   Trimestre         42 non-null     int64 \n",
      " 2   Banda ancha fija  42 non-null     int64 \n",
      " 3   Dial up           42 non-null     int64 \n",
      " 4   Total             42 non-null     int64 \n",
      " 5   Periodo           42 non-null     object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 2.1+ KB\n",
      "None\n",
      "         Año  Trimestre  Banda ancha fija  Dial up      Total\n",
      "count   42.0       42.0              42.0     42.0       42.0\n",
      "mean  2018.8        2.5         8794432.5  21490.2  8815922.7\n",
      "std      3.1        1.1         1742229.3  10136.8  1733188.8\n",
      "min   2014.0        1.0         6362108.0   9991.0  6398398.0\n",
      "25%   2016.0        1.2         7189537.0  11793.0  7218130.8\n",
      "50%   2019.0        2.0         8704688.0  21802.5  8720658.0\n",
      "75%   2021.0        3.0        10376495.8  28593.8 10388730.8\n",
      "max   2024.0        4.0        11621363.0  39324.0 11633156.0\n",
      "Dimensiones del dataframe: (42, 6)\n",
      "Valores nulos por columna\n",
      "Año                 0\n",
      "Trimestre           0\n",
      "Banda ancha fija    0\n",
      "Dial up             0\n",
      "Total               0\n",
      "Periodo             0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Año                0.0\n",
      "Trimestre          0.0\n",
      "Banda ancha fija   0.0\n",
      "Dial up            0.0\n",
      "Total              0.0\n",
      "Periodo            0.0\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Dial-BAf.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\") \n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el formato de fecha para que sea un formato más compatible con Python uniendo la columna fecha con la columna trimestre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Fecha  Banda ancha fija  Dial up     Total\n",
      "0 2024-06-30          11544314    11793  11556107\n",
      "1 2024-03-31          11621363    11793  11633156\n",
      "2 2023-12-31          11535868    11793  11547661\n",
      "3 2023-09-30          11395115    11793  11406908\n",
      "4 2023-06-30          11239781    12116  11251897\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Dial-BAf.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Mapeamos los trimestres al último día de cada trimestre\n",
    "trimestre_map = {1: \"03-31\", 2: \"06-30\", 3: \"09-30\", 4: \"12-31\"}\n",
    "\n",
    "# Convertimos 'Año' a cadena y mapear 'Trimestre' al último día del trimestre\n",
    "if 'Año' in df.columns and 'Trimestre' in df.columns:\n",
    "    df['Año'] = df['Año'].astype(str)\n",
    "    df['Trimestre'] = df['Trimestre'].map(trimestre_map)\n",
    "\n",
    "    # Creamos la columna 'Fecha' combinando 'Año' y 'Trimestre'\n",
    "    df['Fecha'] = pd.to_datetime(df['Año'] + \"-\" + df['Trimestre'])\n",
    "\n",
    "    # Borramos  las columnas 'Año' y 'Trimestre'\n",
    "    df.drop(columns=['Año', 'Trimestre'], inplace=True)\n",
    "\n",
    "    # Reordenamos las columnas \n",
    "    cols = ['Fecha'] + [col for col in df.columns if col != 'Fecha']\n",
    "    df = df[cols]\n",
    "else:\n",
    "    print(\"Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\")\n",
    "\n",
    "    # Eliminamos columna Periodo\n",
    "df.drop(columns=['Periodo'], inplace=True)\n",
    "\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'C:/Users/jrgsi/OneDrive/Escritorio/PROUECTOS HENRY/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales Dial-BAf.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Totales VMD.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Totales VMD.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales VMD.csv\n",
      "       Fecha  Banda ancha fija  Dial up     Total\n",
      "0 2024-06-30          11544314    11793  11556107\n",
      "1 2024-03-31          11621363    11793  11633156\n",
      "2 2023-12-31          11535868    11793  11547661\n",
      "3 2023-09-30          11395115    11793  11406908\n",
      "4 2023-06-30          11239781    12116  11251897\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Fecha             42 non-null     datetime64[ns]\n",
      " 1   Banda ancha fija  42 non-null     int64         \n",
      " 2   Dial up           42 non-null     int64         \n",
      " 3   Total             42 non-null     int64         \n",
      "dtypes: datetime64[ns](1), int64(3)\n",
      "memory usage: 1.4 KB\n",
      "None\n",
      "                               Fecha  Banda ancha fija  Dial up      Total\n",
      "count                             42              42.0     42.0       42.0\n",
      "mean   2019-05-16 06:17:08.571428608         8794432.5  21490.2  8815922.7\n",
      "min              2014-03-31 00:00:00         6362108.0   9991.0  6398398.0\n",
      "25%              2016-10-23 00:00:00         7189537.0  11793.0  7218130.8\n",
      "50%              2019-05-15 12:00:00         8704688.0  21802.5  8720658.0\n",
      "75%              2021-12-08 00:00:00        10376495.8  28593.8 10388730.8\n",
      "max              2024-06-30 00:00:00        11621363.0  39324.0 11633156.0\n",
      "std                              NaN         1742229.3  10136.8  1733188.8\n",
      "Dimensiones del dataframe: (42, 4)\n",
      "Valores nulos por columna\n",
      "Fecha               0\n",
      "Banda ancha fija    0\n",
      "Dial up             0\n",
      "Total               0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Fecha              0.0\n",
      "Banda ancha fija   0.0\n",
      "Dial up            0.0\n",
      "Total              0.0\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales VMD.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\")  \n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el formato de fecha para que sea un formato más compatible con Python uniendo la columna fecha con la columna trimestre y eleminamos la columna Trimestre1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Fecha  Mbps (Media de bajada)\n",
      "0 2024-06-30                   139.2\n",
      "1 2024-03-31                   139.2\n",
      "2 2023-12-31                   139.0\n",
      "3 2023-09-30                   129.7\n",
      "4 2023-06-30                   124.0\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales VMD.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Mapeamos los trimestres al último día de cada trimestre\n",
    "trimestre_map = {1: \"03-31\", 2: \"06-30\", 3: \"09-30\", 4: \"12-31\"}\n",
    "\n",
    "# Convertimos 'Año' a cadena y mapear 'Trimestre' al último día del trimestre\n",
    "if 'Año' in df.columns and 'Trimestre' in df.columns:\n",
    "    df['Año'] = df['Año'].astype(str)\n",
    "    df['Trimestre'] = df['Trimestre'].map(trimestre_map)\n",
    "\n",
    "    # Creamos la columna 'Fecha' combinando 'Año' y 'Trimestre'\n",
    "    df['Fecha'] = pd.to_datetime(df['Año'] + \"-\" + df['Trimestre'])\n",
    "\n",
    "    # Borramos  las columnas 'Año' y 'Trimestre'\n",
    "    df.drop(columns=['Año', 'Trimestre'], inplace=True)\n",
    "\n",
    "    # Reordenamos las columnas \n",
    "    cols = ['Fecha'] + [col for col in df.columns if col != 'Fecha']\n",
    "    df = df[cols]\n",
    "else:\n",
    "    print(\"Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\")\n",
    "\n",
    "# Eliminamos la columna Trimestre.1 \n",
    "df.drop(columns=['Trimestre.1'], inplace=True)\n",
    "\n",
    "#Redondeamos la columna Mbps a un decimal\n",
    "df['Mbps (Media de bajada)'] = df['Mbps (Media de bajada)'].round(1)\n",
    "\n",
    "  # Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'C:/Users/jrgsi/OneDrive/Escritorio/PROUECTOS HENRY/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Totales VMD.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df.head())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Velocidad % por prov.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Velocidad % por prov.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Velocidad % por prov.csv\n",
      "    Año  Trimestre        Provincia  Mbps (Media de bajada)\n",
      "0  2024          2     Buenos Aires                   157.4\n",
      "1  2024          2  Capital Federal                   233.0\n",
      "2  2024          2        Catamarca                    97.4\n",
      "3  2024          2            Chaco                   107.8\n",
      "4  2024          2           Chubut                    21.7\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1008 entries, 0 to 1007\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Año                     1008 non-null   int64  \n",
      " 1   Trimestre               1008 non-null   int64  \n",
      " 2   Provincia               1008 non-null   object \n",
      " 3   Mbps (Media de bajada)  1008 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 31.6+ KB\n",
      "None\n",
      "         Año  Trimestre  Mbps (Media de bajada)\n",
      "count 1008.0     1008.0                  1008.0\n",
      "mean  2018.8        2.5                    24.7\n",
      "std      3.0        1.1                    33.7\n",
      "min   2014.0        1.0                     2.6\n",
      "25%   2016.0        1.0                     4.9\n",
      "50%   2019.0        2.0                    10.1\n",
      "75%   2021.0        3.0                    29.9\n",
      "max   2024.0        4.0                   234.4\n",
      "Dimensiones del dataframe: (1008, 4)\n",
      "Valores nulos por columna\n",
      "Año                       0\n",
      "Trimestre                 0\n",
      "Provincia                 0\n",
      "Mbps (Media de bajada)    0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Año                      0.0\n",
      "Trimestre                0.0\n",
      "Provincia                0.0\n",
      "Mbps (Media de bajada)   0.0\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Velocidad % por prov.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\") \n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el formato de fecha para que sea un formato más compatible con Python uniendo la columna fecha con la columna trimestre y se crea la columna Id_Provincias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provincias en Argentina: ['Buenos Aires' 'Capital Federal' 'Catamarca' 'Chaco' 'Chubut' 'Córdoba'\n",
      " 'Corrientes' 'Entre Ríos' 'Formosa' 'Jujuy' 'La Pampa' 'La Rioja'\n",
      " 'Mendoza' 'Misiones' 'Neuquén' 'Río Negro' 'Salta' 'San Juan' 'San Luis'\n",
      " 'Santa Cruz' 'Santa Fe' 'Santiago Del Estero' 'Tierra Del Fuego'\n",
      " 'Tucumán']\n",
      "Número total de provincias: 24\n",
      "   Id_Provincia        Provincia      Fecha  Mbps (Media de bajada)\n",
      "0             1     Buenos Aires 2024-06-30                   157.4\n",
      "1             2  Capital Federal 2024-06-30                   233.0\n",
      "2             3        Catamarca 2024-06-30                    97.4\n",
      "3             4            Chaco 2024-06-30                   107.8\n",
      "4             5           Chubut 2024-06-30                    21.7\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Velocidad % por prov.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Mapeamos los trimestres al último día de cada trimestre\n",
    "trimestre_map = {1: \"03-31\", 2: \"06-30\", 3: \"09-30\", 4: \"12-31\"}\n",
    "\n",
    "# Convertimos 'Año' a cadena y mapear 'Trimestre' al último día del trimestre\n",
    "if 'Año' in df.columns and 'Trimestre' in df.columns:\n",
    "    df['Año'] = df['Año'].astype(str)\n",
    "    df['Trimestre'] = df['Trimestre'].map(trimestre_map)\n",
    "\n",
    "    # Creamos la columna 'Fecha' combinando 'Año' y 'Trimestre'\n",
    "    df['Fecha'] = pd.to_datetime(df['Año'] + \"-\" + df['Trimestre'])\n",
    "\n",
    "    # Borramos  las columnas 'Año' y 'Trimestre'\n",
    "    df.drop(columns=['Año', 'Trimestre'], inplace=True)\n",
    "\n",
    "    # Reordenamos las columnas \n",
    "    cols = ['Fecha'] + [col for col in df.columns if col != 'Fecha']\n",
    "    df = df[cols]\n",
    "else:\n",
    "    print(\"Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\")\n",
    "\n",
    "\n",
    "# Identificamos todas las provincias en el dataset\n",
    "provincias = df['Provincia'].unique()\n",
    "print(\"Provincias en Argentina:\", provincias)\n",
    "print(\"Número total de provincias:\", len(provincias))\n",
    "\n",
    "# Creamos un diccionario de ID únicos para cada provincia, comenzando desde 1\n",
    "provincia_id_map = {provincia: idx + 1 for idx, provincia in enumerate(provincias)}\n",
    "\n",
    "# Creamos la columna Id_Provincia usando el diccionario\n",
    "df['Id_Provincia'] = df['Provincia'].map(provincia_id_map)\n",
    "\n",
    "# Ordenamos el dataset según el orden de columnas\n",
    "column_order = ['Id_Provincia','Provincia', 'Fecha','Mbps (Media de bajada)']\n",
    "df = df[column_order]\n",
    "\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Velocidad % por prov.csv.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Velocidad_sin_Rangos.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el data set Velocidad_sin_Rangos.csv y realizamos una exploración para ver datos faltantes ,su estructura y visualizar las primeras líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el archivo: H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Velocidad_sin_Rangos.csv\n",
      "    Año  Trimestre     Provincia  Velocidad  Accesos\n",
      "0  2024          2  BUENOS AIRES       75.0     1062\n",
      "1  2024          2  BUENOS AIRES       59.0       59\n",
      "2  2024          2  BUENOS AIRES      480.0        5\n",
      "3  2024          2  BUENOS AIRES        3.5    41735\n",
      "4  2024          2  BUENOS AIRES       18.0     1042\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18884 entries, 0 to 18883\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Año        18884 non-null  int64  \n",
      " 1   Trimestre  18884 non-null  int64  \n",
      " 2   Provincia  18884 non-null  object \n",
      " 3   Velocidad  18874 non-null  float64\n",
      " 4   Accesos    18884 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 737.8+ KB\n",
      "None\n",
      "          Año  Trimestre  Velocidad   Accesos\n",
      "count 18884.0    18884.0    18874.0   18884.0\n",
      "mean   2021.0        2.5       96.2   14123.3\n",
      "std       1.9        1.1      379.7   68563.9\n",
      "min    2017.0        1.0        0.0       0.0\n",
      "25%    2019.0        1.0        4.0      26.0\n",
      "50%    2021.0        2.0       12.3     672.5\n",
      "75%    2023.0        4.0       50.1    6114.0\n",
      "max    2024.0        4.0    10000.0 1346370.0\n",
      "Dimensiones del dataframe: (18884, 5)\n",
      "Valores nulos por columna\n",
      "Año           0\n",
      "Trimestre     0\n",
      "Provincia     0\n",
      "Velocidad    10\n",
      "Accesos       0\n",
      "dtype: int64\n",
      "Porcentaje de valores faltantes por columna:\n",
      " Año         0.0\n",
      "Trimestre   0.0\n",
      "Provincia   0.0\n",
      "Velocidad   0.1\n",
      "Accesos     0.0\n",
      "dtype: float64\n",
      "Número total de filas duplicadas: 0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo \n",
    "archivo= r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Velocidad_sin_Rangos.csv'\n",
    "print(f\"Análisis para el archivo: {archivo}\")  \n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    " # Realizamos el analisis  de el archivo\n",
    "print(df.head())         \n",
    "print(df.info())        \n",
    "print(df.describe())     \n",
    "print(f\"Dimensiones del dataframe: {df.shape}\")\n",
    "\n",
    "# Análisamos el porsentaje de valores nulos valores nulos\n",
    "print(\"Valores nulos por columna\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contamos el valores faltantes\n",
    "missing_values = df.isnull().mean() * 100\n",
    "print(\"Porcentaje de valores faltantes por columna:\\n\", missing_values)\n",
    "\n",
    "# Contamos el número de filas duplicadas\n",
    "num_duplicates = df.duplicated(keep=False).sum()\n",
    "print(\"Número total de filas duplicadas:\", num_duplicates)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador para cada archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provincias en Argentina: ['BUENOS AIRES' 'CABA' 'CATAMARCA' 'CHACO' 'CHUBUT' 'CORDOBA' 'CORRIENTES'\n",
      " 'ENTRE RIOS' 'FORMOSA' 'JUJUY' 'LA PAMPA' 'LA RIOJA' 'MENDOZA' 'MISIONES'\n",
      " 'NEUQUEN' 'RIO NEGRO' 'SALTA' 'SAN JUAN' 'SAN LUIS' 'SANTA CRUZ'\n",
      " 'SANTA FE' 'SANTIAGO DEL ESTERO' 'TIERRA DEL FUEGO' 'TUCUMAN'\n",
      " 'Buenos Aires' 'Capital Federal' 'Catamarca' 'Chaco' 'Chubut' 'Córdoba'\n",
      " 'Corrientes' 'Entre Ríos' 'Formosa' 'Jujuy' 'La Pampa' 'La Rioja'\n",
      " 'Mendoza' 'Misiones' 'Neuquén' 'Río Negro' 'Salta' 'San Juan' 'San Luis'\n",
      " 'Santa Cruz' 'Santa Fe' 'Santiago Del Estero' 'Tierra Del Fuego'\n",
      " 'Tucumán']\n",
      "Número total de provincias: 48\n",
      "       Fecha     Provincia  Velocidad  Accesos  Id_Provincia\n",
      "0 2024-06-30  BUENOS AIRES       75.0     1062             1\n",
      "1 2024-06-30  BUENOS AIRES       59.0       59             1\n",
      "2 2024-06-30  BUENOS AIRES      480.0        5             1\n",
      "3 2024-06-30  BUENOS AIRES        3.5    41735             1\n",
      "4 2024-06-30  BUENOS AIRES       18.0     1042             1\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo CSV\n",
    "archivo = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Velocidad_sin_Rangos.csv'\n",
    "df = pd.read_csv(archivo)\n",
    "\n",
    "# Mapeamos los trimestres al último día de cada trimestre\n",
    "trimestre_map = {1: \"03-31\", 2: \"06-30\", 3: \"09-30\", 4: \"12-31\"}\n",
    "\n",
    "# Convertimos 'Año' a cadena y mapear 'Trimestre' al último día del trimestre\n",
    "if 'Año' in df.columns and 'Trimestre' in df.columns:\n",
    "    df['Año'] = df['Año'].astype(str)\n",
    "    df['Trimestre'] = df['Trimestre'].map(trimestre_map)\n",
    "\n",
    "    # Creamos la columna 'Fecha' combinando 'Año' y 'Trimestre'\n",
    "    df['Fecha'] = pd.to_datetime(df['Año'] + \"-\" + df['Trimestre'])\n",
    "\n",
    "    # Borramos  las columnas 'Año' y 'Trimestre'\n",
    "    df.drop(columns=['Año', 'Trimestre'], inplace=True)\n",
    "\n",
    "    # Reordenamos las columnas \n",
    "    cols = ['Fecha'] + [col for col in df.columns if col != 'Fecha']\n",
    "    df = df[cols]\n",
    "else:\n",
    "    print(\"Error: Las columnas 'Año' y 'Trimestre' no se encontraron en los datos.\")\n",
    "\n",
    "\n",
    "# Identificamos todas las provincias en el dataset\n",
    "provincias = df['Provincia'].unique()\n",
    "print(\"Provincias en Argentina:\", provincias)\n",
    "print(\"Número total de provincias:\", len(provincias))\n",
    "\n",
    "# Creamos un diccionario de ID únicos para cada provincia, comenzando desde 1\n",
    "provincia_id_map = {provincia: idx + 1 for idx, provincia in enumerate(provincias)}\n",
    "\n",
    "# Creamos la columna Id_Provincia usando el diccionario\n",
    "df['Id_Provincia'] = df['Provincia'].map(provincia_id_map)\n",
    "\n",
    "# Ordenamos el dataset según el orden de columnas\n",
    "column_order = ['Id_Provincia','Provincia', 'Fecha','Velocidad','Accesos']\n",
    "\n",
    "# Guardamos el DataFrame final en un archivo CSV\n",
    "output_path = r'H:/PROYECTO INDIVIDUAL DOS/datos/dataset .csv/Internet/Velocidad_sin_Rangos.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
